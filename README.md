# 代码架构与策略深度解析文档

## 1. 程序核心架构：三模块解析

本程序采用了一种高度模块化、分阶段处理的求解策略。整个核心逻辑被清晰地划分为三个独立的模块，它们各司其职，共同协作以生成最终的调度方案。这三个模块分别是：**NPU处理模块**、**迭代模块** 和 **超时用户处理模块**。

### 1.1 NPU处理模块 (`NPUSimulateModule`)

这是整个架构的“战术执行单元”。它专注于解决一个局部的、精细的调度问题：当一个NPU被分配了一组用户后，它应该如何安排这些用户的请求以达成最优。

* **职责**:
    * 回答“**如何处理**”的问题。
    * 为单个NPU和分配给它的用户组，通过精确的、遵循官方规则的时间步进模拟，计算出一份详尽的执行方案和结果。
    * 模块的具体实现（如 `NPUAutoTimeBlockModule`）封装了核心的调度启发式算法，例如如何动态决定`batch_size`、如何排列用户请求等。

* **输入**:
    * `const NPU& npu`: 需要进行模拟的单个NPU实例。
    * `const ProblemData& data`: 全局的问题数据，用于查询延迟、用户DDL等信息。
    * `const std::vector<int>& assigned_users`: 分配给这个NPU的用户ID列表。

* **输出**:
    * `NpuSimulationResult`: 一个包含本次局部模拟所有详细信息的结构体，具体包括：`schedules`, `completed_users`, `timeout_users`, `remaining_samples`, `memory_usage` 等。

### 1.2 迭代模块 (`IteratorModule`)

这是整个架构的“战略决策中心”。它负责在全局视角下，进行宏观的用户分配，决定哪些用户应该被“打包”送往哪个NPU。

* **职责**:
    * 回答“**谁去哪里**”的问题。
    * 定义一套宏观的迭代规则，通过多轮尝试，将系统中的用户尽可能最优地分配给所有可用的NPU。
    * 它不关心NPU内部的具体执行细节，而是将传入的 `NPUSimulateModule` 实例作为一个“黑盒预言机”，来检验其分配决策的可行性。

* **输入**:
    * `const ProblemData& data`: 全局的问题数据。
    * `const NPUSimulateModule& simulator`: 一个具体的NPU处理模块实例，用作评估工具。

* **输出**:
    * `IteratorResult`: 一个包含了迭代分配阶段所有成功结果的结构体，具体包括：`simulate_users` (分配方案) 和 `simulate_results` (每个NPU的模拟报告)。

### 1.3 超时用户处理模块 (`TimeoutHandlerModule`)

这是架构的“收尾与整合单元”。它负责承接迭代模块的结果，进行最后的处理和格式化，确保生成一个覆盖所有用户的、格式完整的最终解。

* **职责**:
    * 整合成功用户的调度方案。
    * 为在迭代分配阶段“掉队”的、无法被完美安置的“超时用户”，提供一个保底的、必须完成的调度方案。

* **输入**:
    * `IteratorResult& iteratorResult`: **迭代模块**产出的结果的引用。

* **输出**:
    * `SolverResult`: 最终的、准备提交的完整解，包含覆盖所有用户的 `solution` 和 `completed_user_count`。

---

## 2. `NPUAutoTimeBlockModule` 内部函数深度解析

在了解了宏观的三大模块之后，我们来深入剖析其中最核心的**NPU处理模块**（在您代码中为 `NPUAutoTimeBlockModule`）其内部的精细决策逻辑。模块的智能正是由以下一系列协同工作的函数（Lambda表达式）所驱动的。

### 2.1 `calculate_handle_time`

* **作用**: 预测一个用户完成其**所有剩余**任务所需的总处理时间。
* **输入**:
    * `user_id`: 用户ID。
    * `batch_size`: 假定的、接下来每次发送请求时使用的批次大小。
* **核心逻辑**:
    1.  计算处理一个`batch_size`批次所需的时间 `batch_handle_time`。
    2.  计算处理完该用户所有`remaining_samples`需要多少个这样的批次（`cnt`）以及最后一个不足`batch_size`的零头批次（`res`）。
    3.  它假设一个流水线式的处理模型，即每批次的处理间隔为 `max(单次处理时间, 通信延迟)`，以此估算出处理完所有批次所需的总时长。
* **在模拟中的角色**: 这是一个**“向前看”的预测函数**。它不是计算当前这一步的耗时，而是对未来进行预估，主要服务于 `can_send` 函数，用来判断一个决策是否会导致未来必定超时。

### 2.2 `calculate_priority`

* **作用**: 在特定时刻 `time`，计算用户 `user_id` 的优先级。
* **输入**:
    * `time`: 当前时刻。
    * `user_id`: 用户ID。
* **核心逻辑**:
    * 公式为 `users[user_id].e - 1.5 * calculate_handle_time(...)`。
    * 这个公式以用户的**截止时间 `e`** 为基础，减去一个与其预估总处理时间成正比的惩罚项。
    * **数值越小，代表越紧急，优先级越高**。
* **在模拟中的角色**: 这是**优先级决策的核心**。它是一个混合策略：
    * **EDF (最早截止时间优先)**: `e` 值小的用户，基础优先级更高。
    * **SJF (最短作业优先)**: 在截止时间相近的用户中，`calculate_handle_time`（预估处理时间）短的用户会获得更高的优先级。

### 2.3 `update_avaliable_users`

* **作用**: 在每个模拟时刻，更新可以被调度器考虑的用户列表。
* **输入**:
    * `time`: 当前时刻。
* **核心逻辑**:
    1.  检查`waiting_users`优先队列（按到达时间排序）。
    2.  将所有到达时间 `<= current_time` 的用户从中取出。
    3.  为这些用户计算当前时刻的优先级（调用`calculate_priority`）。
    4.  将带有新优先级的用户放入 `available_users` 优先队列中。
* **在模拟中的角色**: 这是一个**状态管理器**。它负责将用户从“等待到达”状态，转变为“可以处理”状态，是连接事件与决策的桥梁。

### 2.4 `update_memory`

* **作用**: 在调度器决定发送一个请求后，更新未来一段时间的NPU显存占用情况。
* **输入**:
    * `time`: 请求开始处理的时刻。
    * `user_id`: 用户ID。
    * `batch_size`: 发送的批次大小。
* **核心逻辑**:
    1.  计算这个请求需要占用显存的总时长 `handle_time`。
    2.  计算占用的具体显存量 `memory_cost`。
    3.  在一个 `for` 循环中，将 `memory_usage` 向量从 `time` 到 `time + handle_time` 的每一个元素都加上 `memory_cost`。
* **在模拟中的角色**: 这是一个**资源状态更新器**。它确保了任何一个任务的资源占用，都会在模拟的时间线被准确地记录下来。

### 2.5 `send`

* **作用**: 执行“发送”动作，并更新所有相关的状态变量。
* **输入**:
    * `time`: 请求开始处理的时刻。
    * `user_id`: 用户ID。
    * `batch_size`: 发送的批次大小。
* **核心逻辑**:
    1.  计算真实的发送时间 `send_time` 并创建 `Schedule` 对象存入结果。
    2.  更新用户的 `remaining_samples` 和 `remaining_send_count`。
    3.  判断用户是否已全部完成，如果是，则将其加入 `completed_users` 列表。
    4.  如果未完成，则计算用户下一次可以发送请求的时间，并将其重新放回 `waiting_users` 队列。
    5.  调用 `update_memory` 来更新显存占用。
* **在模拟中的角色**: 这是一个**“事务”执行函数**。它封装了“发送”这一决策所引发的所有连锁状态变化，保证了模拟状态的正确流转。

### 2.6 `can_send`

* **作用**: 判断在当前 `time` 让 `user_id` 发送一个大小为 `batch` 的请求，是否是一个“可行”的决策。
* **输入**:
    * `time`: 当前时刻。
    * `user_id`: 用户ID。
    * `batch`: 準備發送的批次大小。
* **核心逻辑**:
    1.  检查基本条件，如 `batch` 是否大于0，剩余发送次数是否足够等。
    2.  进行一个关键的**远期预测**：调用 `calculate_handle_time` 来估算，如果现在发送了这个 `batch`，那么后续完成所有剩余任务的总时长是否会导致最终超时。
* **在模拟中的角色**: 这是一个**“可行性剪枝”函数或“守门员”**。它阻止调度器做出那些虽然眼前可行，但从长远看必然会导致失败的决策，提高了策略的有效性。

### 2.7 `send_strategy`

* **作用**: 在每个时刻 `time`，根据当前NPU状态和可用用户，做出最终的调度决策。
* **输入**:
    * `time`: 当前时刻。
* **核心逻辑**:
    1.  从 `available_users` 队列中取出当前优先级最高的用户。
    2.  判断NPU是“空闲”还是“繁忙”。
    3.  **如果NPU空闲**: 触发复杂的**动态时间块**逻辑，通过枚举和“性价比”计算，来决定一个最优的 `batch_size` 和处理时长。
    4.  **如果NPU繁忙**: 触发**填充空隙**逻辑，尝试发送一个能在大任务结束前完成的小 `batch_size`。
    5.  调用 `can_send` 验证决策。
    6.  调用 `send` 执行决策。
* **在模拟中的角色**: 这是**调度器的“大脑”**，是所有启发式策略的集合点，负责在每个时间点做出最核心的“发送什么、发多少”的决策。